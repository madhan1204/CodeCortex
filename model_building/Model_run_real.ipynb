{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd91b5e8-1e48-43ff-9f38-34e512ebbc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data:\n",
      "      RT  CH Load     GPM  DeltaCHW  CHWS  CHWR\n",
      "0  319.2     54.4  1367.9       5.6  46.3  51.9\n",
      "1  244.8     45.3  1335.5       4.4  47.1  51.5\n",
      "2  268.5     42.9  1342.5       4.8  47.0  51.8\n",
      "Prediction Data:\n",
      "        RT  CH Load       GPM  DeltaCHW    CHWS    CHWR\n",
      "0  325.784   55.415  1369.001     5.711  46.445  52.156\n",
      "1  243.729   45.455  1337.829     4.373  47.164  51.537\n",
      "2  270.416   43.009  1347.020     4.818  46.921  51.739\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_filename = 'random_forest_model.pkl'\n",
    "rf_loaded = joblib.load(model_filename)\n",
    "\n",
    "# Load new data for prediction\n",
    "new_data = pd.read_csv('testreal.csv')\n",
    "\n",
    "# Print actual target values before dropping them\n",
    "print(\"Actual data:\")\n",
    "print(new_data[['RT', 'CH Load', 'GPM', 'DeltaCHW', 'CHWS', 'CHWR']])  # Access actual values from new_data\n",
    "\n",
    "# Drop the actual target columns from the new data\n",
    "new_x = new_data.drop(columns=['CH Load', 'RT', 'GPM', 'DeltaCHW', 'CHWS', 'CHWR'])\n",
    "\n",
    "# If necessary, rename columns to match the model's training data\n",
    "new_x.rename(columns={\n",
    "    'Temperature [?C]': 'Temperature [Ã¸C]'  # Change as necessary\n",
    "}, inplace=True)\n",
    "\n",
    "# Make predictions\n",
    "predictions = rf_loaded.predict(new_x)\n",
    "\n",
    "# Custom headers for the predicted values\n",
    "custom_headers = ['RT', 'CH Load', 'GPM', 'DeltaCHW', 'CHWS', 'CHWR']\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(predictions, columns=custom_headers)\n",
    "\n",
    "# Display the results with headers\n",
    "print(\"Prediction Data:\")\n",
    "print(predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f0b85-ed03-454b-990f-4509854673a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6df4ed-fcfb-4273-a5e3-fa7353d8357b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89da7530-6e52-483e-9832-631639d81873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the date (YYYY-MM-DD):  2024-09-28\n",
      "Enter the start hour for the time slot (24-hour format):  11\n",
      "Enter the hotel occupancy percentage:  95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model expected features: ['kW_Tot' 'kW_RT' 'CH1' 'CH2' 'CH3' 'CH4' 'kW_CHH' 'kW_CHP' 'kW_CHS'\n",
      " 'kW_CDS' 'kW_CT' 'DeltaCDW' 'CDHI' 'CDLO' 'WBT' 'DeltaCT' 'Hz_ CHP'\n",
      " 'Hz_CHS' 'Hz_CDS' 'Hz_CT' 'Precent_CH' 'Precent_ CHP' 'Precent_CDS'\n",
      " 'Precent_CT' 'RH' 'Temperature' 'WBT_C' 'Hotel_Occupancy' 'weekday'\n",
      " 'year' 'month' 'day' 'hour' 'minute']\n",
      "Input data features: Index(['kW_Tot', 'kW_RT', 'CH1', 'CH2', 'CH3', 'CH4', 'kW_CHH', 'kW_CHP',\n",
      "       'kW_CHS', 'kW_CDS', 'kW_CT', 'DeltaCDW', 'CDHI', 'CDLO', 'WBT',\n",
      "       'DeltaCT', 'Hz_ CHP', 'Hz_CHS', 'Hz_CDS', 'Hz_CT', 'Precent_CH',\n",
      "       'Precent_ CHP', 'Precent_CDS', 'Precent_CT', 'RH', 'Temperature',\n",
      "       'WBT_C', 'Hotel_Occupancy', 'weekday', 'year', 'month', 'day', 'hour',\n",
      "       'minute'],\n",
      "      dtype='object')\n",
      "        RT  CH Load       GPM  DeltaCHW    CHWS    CHWR\n",
      "0  325.262   55.474  1373.271     5.684  46.427  52.111\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "\n",
    "# Function to fetch weather data for a specific time slot\n",
    "def fetch_weather_data(api_key, date_str, start_hour, end_hour):\n",
    "    city = \"Vellore\"\n",
    "    url = f\"http://api.weatherstack.com/current?access_key={api_key}&query={city}&units=m\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        if response.status_code == 200 and 'current' in data:\n",
    "            current_temp = data['current']['temperature']\n",
    "            humidity = data['current']['humidity']\n",
    "            wet_bulb_temp = current_temp - (humidity / 100) * 5\n",
    "\n",
    "            # Create a DataFrame with hourly weather data for the entire day\n",
    "            start_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "            timestamps = [start_time + timedelta(hours=i) for i in range(24)]\n",
    "            weather_data = pd.DataFrame({\n",
    "                \"Timestamps\": timestamps,\n",
    "                \"Temperature\": [current_temp] * len(timestamps),\n",
    "                \"RH\": [humidity] * len(timestamps),\n",
    "                \"WBT_C\": [wet_bulb_temp] * len(timestamps)\n",
    "            })\n",
    "\n",
    "            # Filter for the specific time slot\n",
    "            filtered_data = weather_data[(weather_data['Timestamps'].dt.hour >= start_hour) & \n",
    "                                         (weather_data['Timestamps'].dt.hour < end_hour)]\n",
    "\n",
    "            return filtered_data.iloc[0]  # Return the first row for the selected time slot\n",
    "        else:\n",
    "            raise ValueError(f\"Failed to fetch weather data. Response code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to predict load capacity based on operational metrics and weather data\n",
    "def predict_load_capacity(api_key, date_str, start_hour, end_hour, hotel_occupancy, operational_metrics):\n",
    "    # Fetch weather data for the specific time slot\n",
    "    weather_data = fetch_weather_data(api_key, date_str, start_hour, end_hour)\n",
    "    \n",
    "    if weather_data is None:\n",
    "        return None\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    model_filename = 'random_forest_model.pkl'\n",
    "    rf_loaded = joblib.load(model_filename)\n",
    "\n",
    "    # Extract the feature names the model was trained with\n",
    "    model_features = rf_loaded.feature_names_in_  # This will give us the order of features used during training\n",
    "\n",
    "    # Extract timestamp components (year, month, day, hour, minute) from the weather data\n",
    "    timestamp = weather_data['Timestamps']\n",
    "    year = timestamp.year\n",
    "    month = timestamp.month\n",
    "    day = timestamp.day\n",
    "    hour = timestamp.hour\n",
    "    minute = timestamp.minute\n",
    "\n",
    "    # Add weekday to the input data\n",
    "    input_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    weekday = input_date.weekday()  # Returns an integer (0 = Monday, 6 = Sunday)\n",
    "\n",
    "    # Add timestamp components and weekday to the operational metrics\n",
    "    operational_metrics['year'] = year\n",
    "    operational_metrics['month'] = month\n",
    "    operational_metrics['day'] = day\n",
    "    operational_metrics['hour'] = hour\n",
    "    operational_metrics['minute'] = minute\n",
    "    operational_metrics['weekday'] = weekday  # Add weekday (0-6) as a feature\n",
    "\n",
    "    # Add weather data to operational metrics\n",
    "    operational_metrics['Temperature'] = weather_data['Temperature']\n",
    "    operational_metrics['RH'] = weather_data['RH']\n",
    "    operational_metrics['WBT_C'] = weather_data['WBT_C']\n",
    "\n",
    "    # Add hotel occupancy to the operational metrics\n",
    "    operational_metrics['Hotel_Occupancy'] = hotel_occupancy\n",
    "\n",
    "    # Convert the operational metrics to a DataFrame\n",
    "    input_data = pd.DataFrame([operational_metrics])\n",
    "\n",
    "    # Reorder the columns to match the model's feature order\n",
    "    input_data = input_data[model_features]  # Reordering columns to match model feature order\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = rf_loaded.predict(input_data)\n",
    "\n",
    "    # Custom headers for the predicted values (adjust based on model's expected output)\n",
    "    custom_headers = ['RT', 'CH Load', 'GPM', 'DeltaCHW', 'CHWS', 'CHWR']\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Create a DataFrame for the predictions\n",
    "    predictions_df = pd.DataFrame(predictions, columns=custom_headers)\n",
    "\n",
    "    return predictions_df\n",
    "\n",
    "# Example usage:\n",
    "api_key = \"5460889761385624e130f4ee0e0ad810\" \n",
    "date_input = input(\"Enter the date (YYYY-MM-DD): \")\n",
    "start_hour = int(input(\"Enter the start hour for the time slot (24-hour format): \"))\n",
    "end_hour = start_hour + 1  # End hour is the next hour\n",
    "hotel_occupancy = float(input(\"Enter the hotel occupancy percentage: \"))\n",
    "\n",
    "# Example operational metrics (adjusted to match the actual headers with space corrections)\n",
    "operational_metrics_data = {\n",
    "    'kW_Tot': 260.2,\n",
    "    'kW_RT': 0.815,\n",
    "    'CH1': 1,\n",
    "    'CH2': 0,\n",
    "    'CH3': 0,\n",
    "    'CH4': 0,\n",
    "    'kW_CHH': 184.5,\n",
    "    'kW_CHP': 24.3,\n",
    "    'kW_CHS': 0,\n",
    "    'kW_CDS': 31.6,\n",
    "    'kW_CT': 19.8,\n",
    "    'DeltaCDW': 5.6,\n",
    "    'CDHI': 87.6,\n",
    "    'CDLO': 82,\n",
    "    'WBT': 76.1,   # Wet Bulb Temperature (Â°C)\n",
    "    'DeltaCT': -5.9,\n",
    "    'Hz_ CHP': 48,  # Ensure this matches the feature name in the model\n",
    "    'Hz_CHS': 0,\n",
    "    'Hz_CDS': 47,\n",
    "    'Hz_CT': 48,\n",
    "    'Precent_ CHP': 9.3,  # Ensure this matches the feature name in the model\n",
    "    'Precent_CH': 70.9,\n",
    "    'Precent_CDS': 12.2,\n",
    "    'Precent_CT': 7.6,\n",
    "}\n",
    "\n",
    "# Call the function to predict load capacity\n",
    "predicted_load = predict_load_capacity(api_key, date_input, start_hour, end_hour, hotel_occupancy, operational_metrics_data)\n",
    "print(predicted_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bf498-9b46-4b15-bfab-d749a3aab817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58ef876e-268a-467e-bc6f-97e76a989659",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check if all model features are present in the input data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_features \u001b[38;5;241m=\u001b[39m rf_loaded\u001b[38;5;241m.\u001b[39mfeature_names_in_ \n\u001b[1;32m----> 4\u001b[0m missing_features \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m extra_features \u001b[38;5;241m=\u001b[39m [feature \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m input_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_features]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_features:\n",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check if all model features are present in the input data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_features \u001b[38;5;241m=\u001b[39m rf_loaded\u001b[38;5;241m.\u001b[39mfeature_names_in_ \n\u001b[1;32m----> 4\u001b[0m missing_features \u001b[38;5;241m=\u001b[39m [feature \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m model_features \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_data\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[0;32m      5\u001b[0m extra_features \u001b[38;5;241m=\u001b[39m [feature \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m input_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m feature \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_features]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_features:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if all model features are present in the input data\n",
    "model_features = rf_loaded.feature_names_in_ \n",
    "\n",
    "missing_features = [feature for feature in model_features if feature not in input_data.columns]\n",
    "extra_features = [feature for feature in input_data.columns if feature not in model_features]\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"Missing features: {missing_features}\")\n",
    "if extra_features:\n",
    "    print(f\"Extra features: {extra_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640355a-3d2c-4146-b3a0-f0db1e8162d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
